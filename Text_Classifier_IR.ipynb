{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cbb2b04ce1d4669a753f2132fcfdb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59e0bcd5078f40cb89e58e4d2f79548e",
              "IPY_MODEL_c2897dac25c840f49afbccc1c633a699",
              "IPY_MODEL_b82e6f3fb03845ce80e43aab475ad9a8"
            ],
            "layout": "IPY_MODEL_6bb3b1dfa7334bceaa9b62eabe1c3e1e"
          }
        },
        "59e0bcd5078f40cb89e58e4d2f79548e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba68ee429e84b418262d0e3167224e7",
            "placeholder": "​",
            "style": "IPY_MODEL_9956777e999e47c9a08081bb49747403",
            "value": " 12%"
          }
        },
        "c2897dac25c840f49afbccc1c633a699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63088f3cef70497bbc1f406e263fae41",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_179747534905486dbc4c862a5d926224",
            "value": 23
          }
        },
        "b82e6f3fb03845ce80e43aab475ad9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ed673536eb430aa02ccd17aa92e482",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0a65e917ce495d9b9a6de126e6a797",
            "value": " 23/200 [00:28&lt;03:34,  1.21s/it]"
          }
        },
        "6bb3b1dfa7334bceaa9b62eabe1c3e1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba68ee429e84b418262d0e3167224e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9956777e999e47c9a08081bb49747403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63088f3cef70497bbc1f406e263fae41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179747534905486dbc4c862a5d926224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75ed673536eb430aa02ccd17aa92e482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0a65e917ce495d9b9a6de126e6a797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hrishikesh-Harsh/Text_Classification_IR/blob/main/Text_Classifier_IR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use TF-IDF as prescribed\n",
        "### Treat Abstract, Key and Title differently\n",
        "### Order: $Key > Abstract ≈ Title$\n",
        "### Hence, $W_k > W_a \\approx W_t$\n",
        "### For TF, we can use $TF = 1 + log(n_t*W_t + n_k*W_k + n_a*W_a)$\n",
        "### One More Hyper-parameter to vary is Window size for (Word,Word) pairs\n",
        "### Use $3$ different Window sizes for $Key, Abstract, Title$: $Win_k, Win_a, Win_t$"
      ],
      "metadata": {
        "id": "bvuRuAI6OwL1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXkm6ja9Rone"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "!pip3 install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sSg_DXcQMJt",
        "outputId": "3b7c9162-d95a-494d-b78e-3274ed239888"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kMJj6iPgQMPv",
        "outputId": "248bb907-97ce-41e4-ecce-2bebebba15c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "import csv\n",
        "import math\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import scipy.sparse as sp\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "3hihn_ln9prw",
        "outputId": "f699c8f7-e0a8-4391-e56c-aa67ef77f8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "NUM_LAYERS = 2 \n",
        "HIDDEN_DIM = 440\n",
        "DROP_OUT = 0.55\n",
        "LR = 0.02\n",
        "WEIGHT_DECAY = 0\n",
        "EARLY_STOPPING = 10\n",
        "NUM_EPOCHS = 200\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_ratio = 0.7\n",
        "test_ratio = 0.3\n",
        "N = 206\n",
        "\n",
        "train_N = int(train_ratio*N)\n",
        "test_N = N-train_N\n",
        "\n",
        "wt_k = 9    # Weight to be given to Keywords in tf score\n",
        "wt_t = 3    # Weight to be given to Title in tf score\n",
        "wt_a = 1    # Weight to be given to Abstract in tf score\n",
        "window_size = 20 # Window size for PMI calculation"
      ],
      "metadata": {
        "id": "gA05JNJYPlfU"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "# Loading original .csv file\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/PubMed.csv',encoding='Latin1')\n",
        "type(file)\n",
        "csvreader = csv.reader(file)"
      ],
      "metadata": {
        "id": "WFX7tvxa-G_h"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "# Set of stopwords to be removed\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "wAdO0mSn-HFS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "# Just the first line of the .csv file (Column Names)\n",
        "header = []\n",
        "header = next(csvreader)"
      ],
      "metadata": {
        "id": "xKFHS9krAgxu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "# vocab_words would be a set of all distinct words found in the dataset/.csv file minus the stopwords\n",
        "vocab_words = set()\n",
        "vocab_words_list = []"
      ],
      "metadata": {
        "id": "tAzHoVJ6JEZq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "rows = []\n",
        "index = 0\n",
        "title = []\n",
        "keyword = []\n",
        "abstract = []\n",
        "for r in csvreader: \n",
        "  r_sub = []\n",
        "  r[2] = r[2].replace('.',' ')\n",
        "  r[2] = r[2].replace(',',' ')\n",
        "  r[2] = r[2].replace(';',' ')\n",
        "  r[2] = r[2].replace('|',' ')\n",
        "  r[2] = r[2].replace('<',' ')\n",
        "  r[2] = r[2].replace('>',' ')\n",
        "  r[2] = r[2].replace(':',' ')\n",
        "  r[2] = r[2].replace('=',' ')\n",
        "  r[2] = r[2].replace('(',' ')\n",
        "  r[2] = r[2].replace(')',' ')\n",
        "  r[2] = r[2].replace('[',' ')\n",
        "  r[2] = r[2].replace(']',' ')\n",
        "  r[2] = r[2].replace('?',' ')\n",
        "\n",
        "\n",
        "  r[3] = r[3].replace('.',' ')\n",
        "  r[3] = r[3].replace(',',' ')\n",
        "  r[3] = r[3].replace(';',' ')\n",
        "  r[3] = r[3].replace('|',' ')\n",
        "  r[3] = r[3].replace('<',' ')\n",
        "  r[3] = r[3].replace('>',' ')\n",
        "  r[3] = r[3].replace(':',' ')\n",
        "  r[3] = r[3].replace('=',' ')\n",
        "  r[3] = r[3].replace('(',' ')\n",
        "  r[3] = r[3].replace(')',' ')\n",
        "  r[3] = r[3].replace('[',' ')\n",
        "  r[3] = r[3].replace(']',' ')\n",
        "  r[3] = r[3].replace('?',' ')\n",
        "\n",
        "  r[4] = r[4].replace('.',' ')\n",
        "  r[4] = r[4].replace(',',' ')\n",
        "  r[4] = r[4].replace(';',' ')\n",
        "  r[4] = r[4].replace('|',' ')\n",
        "  r[4] = r[4].replace('<',' ')\n",
        "  r[4] = r[4].replace('>',' ')\n",
        "  r[4] = r[4].replace(':',' ')\n",
        "  r[4] = r[4].replace('=',' ')\n",
        "  r[4] = r[4].replace('(',' ')\n",
        "  r[4] = r[4].replace(')',' ')\n",
        "  r[4] = r[4].replace('[',' ')\n",
        "  r[4] = r[4].replace(']',' ')\n",
        "  r[4] = r[4].replace('?',' ')\n",
        "\n",
        "  words_title = word_tokenize(r[2])     # Tokenize the Title of that doc (row)\n",
        "  words_keyword = word_tokenize(r[3])   # Tokenize the Keywords of that doc (row)\n",
        "  words_abstract = word_tokenize(r[4])  # Tokenize the Abstract of that doc (row)\n",
        "\n",
        "  title.append([])\n",
        "  keyword.append([])\n",
        "  abstract.append([])\n",
        "\n",
        "  w_t = \"\"\n",
        "  w_k = \"\"\n",
        "  w_a = \"\"\n",
        "\n",
        "  ''' \n",
        "      - Adding all non-stop-words to the vocabulary\n",
        "      - Also maintaining doc-wise collection of Keywords, Title and Abstract words \n",
        "  '''\n",
        "\n",
        "  for w in words_title:\n",
        "    if w not in stop_words and w!=\"'s\":\n",
        "        w_t = w_t + w + \" \"\n",
        "        vocab_words.add(w)\n",
        "        # vocab_words_list.append(w)\n",
        "        title[index].append(w)\n",
        "  \n",
        "  for w in words_keyword:\n",
        "    if w not in stop_words and w!=\"'s\":\n",
        "        w_k = w_k + w + \" \"\n",
        "        vocab_words.add(w)\n",
        "        # vocab_words_list.append(w)\n",
        "        keyword[index].append(w)\n",
        "\n",
        "  for w in words_abstract:\n",
        "    if w not in stop_words and w!=\"'s\":\n",
        "        w_a = w_a + w + \" \"\n",
        "        vocab_words.add(w)\n",
        "        # vocab_words_list.append(w)\n",
        "        abstract[index].append(w)\n",
        "  \n",
        "  index=index+1\n",
        "\n",
        "  '''\n",
        "    - Creating 'rows' to write back to Clean File\n",
        "  '''\n",
        "  for i in range(0,len(r)):\n",
        "    if(i==2):\n",
        "      r_sub.append(w_t)\n",
        "    elif(i==3):\n",
        "      r_sub.append(w_k)\n",
        "    elif(i==4):\n",
        "      r_sub.append(w_a) \n",
        "    else:\n",
        "      r_sub.append(r[i])\n",
        "    \n",
        "  rows.append(r_sub)\n"
      ],
      "metadata": {
        "id": "sto5tlbyAwu_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "train_docs = []\n",
        "test_docs = []\n",
        "\n",
        "train_docs = rows[:train_N]\n",
        "test_docs = rows[train_N:train_N+test_N]\n"
      ],
      "metadata": {
        "id": "DwPWp9DppA57"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = []"
      ],
      "metadata": {
        "id": "UENi3ZL0H2lk"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_N)\n",
        "print(train_N+test_N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QveskD_DceyQ",
        "outputId": "d4dd5673-f366-42c4-f5ec-31ef334bfb99"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_labels_train=[]\n",
        "for i,r in enumerate(train_docs):\n",
        "  original_labels_train.append(int(r[5]))\n",
        "  all_labels.append(int(r[5]))"
      ],
      "metadata": {
        "id": "AaxC4asWn6-H"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_labels_test=[]\n",
        "for i,r in enumerate(test_docs):\n",
        "  original_labels_test.append(int(r[5]))\n",
        "  all_labels.append(int(r[5]))"
      ],
      "metadata": {
        "id": "SjojRKYVwKyk"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhwOvndd923U",
        "outputId": "8b97053f-5746-4799-c798-9cc056a384a6"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_labels))"
      ],
      "metadata": {
        "id": "kF-3U9w_LIMO",
        "outputId": "3677e984-2348-498c-f22f-28b999292a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Labels_1 = original_labels_train.count(1)+original_labels_test.count(1)\n",
        "Labels_0 = original_labels_train.count(0)+original_labels_test.count(0)"
      ],
      "metadata": {
        "id": "2vUYwfthIqKc"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1:\",Labels_1,\"| 0:\",Labels_0)"
      ],
      "metadata": {
        "id": "LgHLTKFQJWyo",
        "outputId": "0485d842-ce20-441b-9f16-6ba160024e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: 116 | 0: 90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels=np.unique(original_labels_train)\n",
        "\n",
        "num_class = len(unique_labels)\n",
        "lEnc = LabelEncoder()\n",
        "lEnc.fit(unique_labels)\n",
        "\n",
        "print(unique_labels)\n",
        "print(lEnc.transform(unique_labels))\n",
        "\n",
        "train_labels = lEnc.transform(original_labels_train)\n",
        "test_labels = lEnc.transform(original_labels_test)\n",
        "\n",
        "labels = train_labels.tolist()+test_labels.tolist()\n",
        "labels = torch.LongTensor(labels).to(device)"
      ],
      "metadata": {
        "id": "1YvJSvXJwhfr",
        "outputId": "f2f42790-1193-4eeb-8929-79a9e371d1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "vocab_words_list=[]\n",
        "for wd in vocab_words:\n",
        "  vocab_words_list.append(wd)"
      ],
      "metadata": {
        "id": "V6yddrnwBX3b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "# Globals\n",
        "docs_size = len(rows)\n",
        "vocab_size = len(vocab_words)"
      ],
      "metadata": {
        "id": "uTf_qtYyJ0kj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  To write back to Clean File\n",
        "'''\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/PubMed_Clean.csv', 'w', newline='')\n",
        "writer = csv.writer(file)\n",
        "writer.writerow(header)\n",
        "\n",
        "for r in rows:\n",
        "  writer.writerow(r)\n"
      ],
      "metadata": {
        "id": "W_ymGTwQDA4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "'''\n",
        "  Create a dict to store {word: (ID, idf)} mapping\n",
        "'''\n",
        "dict_vocab = {}\n",
        "\n",
        "for i,w in enumerate(vocab_words):\n",
        "  dict_vocab[w]=(i,0)"
      ],
      "metadata": {
        "id": "xeAiaPkDIOBi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,w in enumerate(vocab_words):\n",
        "  if(i>5):\n",
        "    break\n",
        "  print(w)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "3vNg82HsthO6",
        "outputId": "4b63e10d-a392-46d3-8876-2e207e93937e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimates\n",
            "Neuroticism\n",
            "saves\n",
            "postmortem\n",
            "belief\n",
            "inter-\n",
            "59972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/IR_Project/dataset/idf.csv', 'w', newline='') \n",
        "writer = csv.writer(file) \n",
        "writer.writerow([\"word\",\"idf\"])\n",
        "for wd in dict_vocab: \n",
        "  count = 0\n",
        "  for i,doc in enumerate(rows):\n",
        "    flag = 0 \n",
        "    for w_t in title[i]:\n",
        "      if(wd==w_t):\n",
        "        count=count+1\n",
        "        flag = 1\n",
        "        break \n",
        "\n",
        "    if(flag==1):\n",
        "      continue \n",
        "\n",
        "    for w_k in keyword[i]:\n",
        "      if(wd==w_k):\n",
        "        count=count+1\n",
        "        flag = 1\n",
        "        break\n",
        "\n",
        "    if(flag==1):\n",
        "      continue \n",
        "\n",
        "    for w_a in abstract[i]:\n",
        "      if(wd==w_a):\n",
        "        count=count+1\n",
        "        flag = 1\n",
        "        break\n",
        "\n",
        "    if(flag==1):\n",
        "      continue\n",
        "\n",
        "  (id,idf) = dict_vocab[wd]\n",
        "  if(count==0):\n",
        "    idf = 0\n",
        "  else:\n",
        "    idf = math.log((docs_size/count),10) \n",
        "  dict_vocab[wd] = (id,idf)\n",
        "  templine=[]\n",
        "  templine.append(wd)\n",
        "  templine.append(idf)\n",
        "  writer.writerow(templine)\n",
        "  print(id,templine)\n",
        "  count = 0\n",
        "writer.writerow(\"fine\")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "KozY8dLB8Lfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/idf.csv',encoding='Latin1')\n",
        "type(file)\n",
        "csvreader = csv.reader(file)\n",
        "\n",
        "header = []\n",
        "header = next(csvreader)"
      ],
      "metadata": {
        "id": "CohPXaSOrZ78"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "for val in dict_vocab: \n",
        "  r = next(csvreader)\n",
        "  if(r[0] not in dict_vocab):\n",
        "    continue\n",
        "  if(r[1]=='i'):\n",
        "    break\n",
        "  (id,idf) = dict_vocab[r[0]]\n",
        "  idf = float(r[1])\n",
        "  dict_vocab[r[0]] = (id,idf)"
      ],
      "metadata": {
        "id": "N61pPwI5r4hS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,ele in enumerate(dict_vocab):\n",
        "  if(i==5):\n",
        "    break;\n",
        "  \n",
        "  print(ele,\",\",dict_vocab[ele])"
      ],
      "metadata": {
        "id": "pzCpsOziIZ4Q",
        "outputId": "d58ce083-ed85-470c-df6b-54357682cf48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimates , (0, 3.247138226100887)\n",
            "Neuroticism , (1, 3.468986975717243)\n",
            "saves , (2, 3.468986975717243)\n",
            "postmortem , (3, 3.167956980053262)\n",
            "belief , (4, 2.312639774857319)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "Adj_Matrix = np.zeros((docs_size+vocab_size,docs_size+vocab_size))\n",
        "weights = []\n",
        "row_list = []\n",
        "col_list = []"
      ],
      "metadata": {
        "id": "r9UXxGeAONi7"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Adj_Matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UseMlUhyGzKJ",
        "outputId": "26a74a11-a0e2-468b-c7d6-026d46d0441f"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68805, 68805)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "for i,doc in enumerate(rows):\n",
        "  for w_k in keyword[i]:\n",
        "    Adj_Matrix[i,dict_vocab[w_k][0]+docs_size] += wt_k\n",
        "    Adj_Matrix[dict_vocab[w_k][0]+docs_size,i] += wt_k\n",
        "\n",
        "  for w_t in title[i]:\n",
        "    Adj_Matrix[i,dict_vocab[w_t][0]+docs_size] += wt_t\n",
        "    Adj_Matrix[dict_vocab[w_t][0]+docs_size,i] += wt_t\n",
        "\n",
        "  for w_a in abstract[i]:\n",
        "    Adj_Matrix[i,dict_vocab[w_a][0]+docs_size] += wt_a\n",
        "    Adj_Matrix[dict_vocab[w_a][0]+docs_size,i] += wt_a\n",
        "  # # wt = 0\n",
        "  # for w_k in keyword[i]:\n",
        "  #   # wt += wt_k\n",
        "  #   # weights.append(wt*dict_vocab[w_k][1])\n",
        "  #   row_list.append(i)\n",
        "  #   col_list.append(dict_vocab[w_k][0]+docs_size)\n",
        "  #   x=pow(10,Adj_Matrix(i,dict_vocab[w_k][0]+docs_size)-1)\n",
        "  #   Adj_Matrix[i][dict_vocab[w_k][0]+docs_size]=x+wt_k\n",
        "  #   Adj_Matrix[i][dict_vocab[w_k][0]+docs_size]=1+math.log(Adj_Matrix[i][dict_vocab[w_k][0]+docs_size])\n",
        "  # for w_t in title[i]:\n",
        "  #   # wt += wt_t\n",
        "  #   # weights.append(wt*dict_vocab[w_t][1])\n",
        "  #   row_list.append(i)\n",
        "  #   col_list.append(dict_vocab[w_t][0]+docs_size)\n",
        "  # for w_a in abstract[i]:\n",
        "  #   # wt += wt_a\n",
        "  #   # weights.append(wt*dict_vocab[w_a][1])\n",
        "  #   row_list.append(i)\n",
        "  #   col_list.append(dict_vocab[w_a][0]+docs_size)\n"
      ],
      "metadata": {
        "id": "MvP0Cz_2OSHq"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run\n",
        "for i in range(0,docs_size):\n",
        "  for j in range(docs_size,Adj_Matrix.shape[0]):\n",
        "    if(Adj_Matrix[i,j]!=0):\n",
        "      wd = vocab_words_list[j-docs_size]\n",
        "      idf = dict_vocab[wd][1]\n",
        "      Adj_Matrix[i,j] = (1+math.log(Adj_Matrix[i,j],10))*idf\n",
        "      Adj_Matrix[j,i]=Adj_Matrix[i,j]\n"
      ],
      "metadata": {
        "id": "akrynkoDu-Ng"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word co-occurence with context windows\n",
        "'''\n",
        "windows = []\n",
        "\n",
        "for row in rows:\n",
        "    content=row[2]+\" \"+row[3]+\" \"+row[4]\n",
        "    words = content.split()\n",
        "    length = len(words)\n",
        "    if length <= window_size: \n",
        "        windows.append(words)\n",
        "    else:\n",
        "        # print(length, length - window_size + 1)\n",
        "        for j in range(length - window_size + 1):\n",
        "            window = words[j: j + window_size]\n",
        "            windows.append(window)\n",
        "            # print(window)\n",
        "\n",
        "print(len(windows))\n",
        "\n",
        "#calculating p(i) , word_window_freq has the number of windows a particular word appears in across all windows.\n",
        "word_window_freq = {}\n",
        "k = 0\n",
        "for window in windows:\n",
        "    appeared = set()\n",
        "    for i in range(len(window)):\n",
        "        if window[i] in appeared:\n",
        "            continue\n",
        "        if window[i] in word_window_freq:\n",
        "            word_window_freq[window[i]] += 1\n",
        "        else:\n",
        "            word_window_freq[window[i]] = 1\n",
        "        appeared.add(window[i])\n",
        "    # print(\"k=\",k)  \n",
        "    # k+=1\n",
        "print(len(word_window_freq))\n",
        "\n",
        "word_pair_count = {}\n",
        "k1=0\n",
        "for window in windows:\n",
        "    for i in range(1, len(window)):\n",
        "        for j in range(0, i):\n",
        "            word_i = window[i] #ith word in window\n",
        "            word_i_id = dict_vocab[word_i][0]\n",
        "            word_j = window[j] #jth word in range 0-i in the same window\n",
        "            word_j_id = dict_vocab[word_j][0]\n",
        "            if word_i_id == word_j_id:\n",
        "                continue\n",
        "            word_pair_str = str(word_i_id) + ',' + str(word_j_id) #concat id and use it to count a pair or p(i,j)\n",
        "            if word_pair_str in word_pair_count: #word_pair_count stores number of pairs along with number of times they appear.\n",
        "                word_pair_count[word_pair_str] += 1\n",
        "            else:\n",
        "                word_pair_count[word_pair_str] = 1\n",
        "            # two orders\n",
        "            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n",
        "            if word_pair_str in word_pair_count:\n",
        "                word_pair_count[word_pair_str] += 1\n",
        "            else:\n",
        "                word_pair_count[word_pair_str] = 1\n",
        "    # k1+=1\n",
        "    # print(\"k1=\",k1)    \n",
        "print(len(word_pair_count))\n",
        "'''\n",
        "\n",
        "# row = []\n",
        "# col = []\n",
        "# weight = []\n",
        "\n",
        "# pmi as weights\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of6lRt0325On",
        "outputId": "543a4d44-4147-49a2-a391-ea4afb1abdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "829994\n",
            "59972\n",
            "13434816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "num_window = len(windows)\n",
        "\n",
        "for key in word_pair_count:\n",
        "    temp = key.split(',')\n",
        "    i = int(temp[0])\n",
        "    j = int(temp[1])\n",
        "    # print(\"pair(i,j)=\",i,j)\n",
        "    count = word_pair_count[key] #p(i,j)\n",
        "    word_freq_i = word_window_freq[vocab_words_list[i]] #p(i)\n",
        "    word_freq_j = word_window_freq[vocab_words_list[j]] #p(j)\n",
        "    pmi = math.log((1.0 * count / num_window) /(1.0 * word_freq_i * word_freq_j/(num_window * num_window)),10) #adj(i,j)\n",
        "    if pmi <= 0:\n",
        "        continue\n",
        "    # Adj_Matrix[docs_size+i][docs_size+j]=pmi\n",
        "    weights.append(pmi)\n",
        "    row_list.append(docs_size+i)\n",
        "    col_list.append(docs_size+j)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "7x8TSh9qd3cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(weights))\n",
        "print(len(row_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TvYbxBtzHBy",
        "outputId": "c3e4a7f8-aa2c-411f-f197-ddbb4996d468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11465454\n",
            "11465454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/pmi.csv', 'w', newline='') \n",
        "writer = csv.writer(file) \n",
        "writer.writerow([\"weight\",\"row\",\"col\"])\n",
        "for i,weight_pmi in enumerate(weights):\n",
        "  line=[]\n",
        "  line.append(weights[i])\n",
        "  line.append(row_list[i])\n",
        "  line.append(col_list[i])\n",
        "  writer.writerow(line)\n",
        "file.close()\n",
        "'''"
      ],
      "metadata": {
        "id": "bXRekUt-mD6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights=[]\n",
        "row_list=[]\n",
        "col_list=[]\n",
        "print(len(weights))"
      ],
      "metadata": {
        "id": "lRMD46IgDibD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2820795d-bbe5-496d-a1b6-92e2bbfedf3b"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/pmi.csv',encoding='Latin1')\n",
        "type(file)\n",
        "csvreader = csv.reader(file)\n",
        "\n",
        "header = []\n",
        "header = next(csvreader)\n"
      ],
      "metadata": {
        "id": "9PZzkXhUxpSp"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "weights=[]\n",
        "row_list=[]\n",
        "col_list=[]\n",
        "count_skip=0\n",
        "for r in csvreader:\n",
        "    weights.append(float(r[0]))\n",
        "    row_list.append(int(r[1]))\n",
        "    col_list.append(int(r[2]))\n",
        "file.close()\n",
        "print(weights[:5])\n",
        "print(row_list[:5])\n",
        "print(col_list[:5])\n",
        "print(len(weights))"
      ],
      "metadata": {
        "id": "SG7FXo3IJEL6",
        "outputId": "044181d4-e8e1-4a20-934d-0f370e784015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2854235499355359, 0.2854235499355359, 0.27660597339490123, 0.27660597339490123, 0.3417359872561016]\n",
            "[33789, 34119, 33789, 62635, 62357]\n",
            "[34119, 33789, 62635, 33789, 34119]\n",
            "11465454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(weights))\n",
        "print(Adj_Matrix.shape)"
      ],
      "metadata": {
        "id": "9E28X3A2Cc_c",
        "outputId": "e97289d8-0186-4b9c-c3a5-28552c5c4f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11465454\n",
            "(68805, 68805)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "from scipy.sparse import csr_matrix\n",
        "Adj_Mat=csr_matrix(Adj_Matrix)"
      ],
      "metadata": {
        "id": "KkgCixAQrhs2"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Adj_Mat.shape)"
      ],
      "metadata": {
        "id": "sppwyPooIN9Y",
        "outputId": "ba3ad6c7-3a47-4187-a79c-0efb1020fcaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68805, 68805)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AdjMat1=Adj_Mat\n",
        "print(docs_size)\n",
        "print(len(vocab_words_list))"
      ],
      "metadata": {
        "id": "lgTfAY8MIbKH",
        "outputId": "79fe47e1-aa82-48ce-bc9c-36c91b7f7bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8833\n",
            "59972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "Adj_Matrix = sp.csr_matrix((weights, (row_list, col_list)), shape=(docs_size+len(vocab_words_list), docs_size+len(vocab_words_list)))\n",
        "\n",
        "# build symmetric adjacency matrix\n",
        "Adj_Matrix = Adj_Matrix + Adj_Matrix.T.multiply(Adj_Matrix.T > Adj_Matrix) - Adj_Matrix.multiply(Adj_Matrix.T > Adj_Matrix)"
      ],
      "metadata": {
        "id": "pBawb0WrQYwT"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Adj_Mat.shape)\n",
        "print(Adj_Matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY7RHzBSGhNZ",
        "outputId": "80a025e5-0e68-431d-ea99-21fe58f0ed4c"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68805, 68805)\n",
            "(68805, 68805)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "Adj_Matrix=Adj_Mat+Adj_Matrix"
      ],
      "metadata": {
        "id": "8iF4mNfOv62N"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "Adj_Matrix=csr_matrix(Adj_Matrix)"
      ],
      "metadata": {
        "id": "G__jRVAVwB-0"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available:\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('Please set GPU via Edit -> Notebook Settings.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzLvTyd2Cugq",
        "outputId": "9e8bde63-c005-4e05-8f79-8cecd303a082"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_labels))\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f805Ay38wqo6",
        "outputId": "c48a404f-bf9c-49cf-e91c-fbdebdfae766"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83\n",
            "(83,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalise(Adj_Matrix):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    Adj_Matrix = sp.coo_matrix(Adj_Matrix)\n",
        "    rowsum = np.array(Adj_Matrix.sum(1))\n",
        "    D = np.power(rowsum, -0.5).flatten()\n",
        "    D[np.isinf(D)] = 0.\n",
        "    D_Factor = sp.diags(D)\n",
        "    return Adj_Matrix.dot(D_Factor).transpose().dot(D_Factor).tocoo(), D\n",
        "    \n",
        "Adj_Matrix, D = normalise(Adj_Matrix + sp.eye(Adj_Matrix.shape[0]))"
      ],
      "metadata": {
        "id": "nmmG4LyK-nZu"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)\n",
        "for i in range(0,labels.shape[0]):\n",
        "  labels[i] = 1.0 - labels[i]\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "FmCwOQ6MMjS3",
        "outputId": "bbd634a1-c790-4323-b508-75a15d150678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1\n",
            " 1 0 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0]\n",
            "[1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 0 1 0 1 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def purity_score(y_true, y_pred):\n",
        "    # compute contingency matrix (also called confusion matrix)\n",
        "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
        "    print(contingency_matrix)\n",
        "    # return purity\n",
        "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n"
      ],
      "metadata": {
        "id": "zoFvqcu2IXeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = purity_score(all_labels,labels)\n",
        "print(\"score =\",score)"
      ],
      "metadata": {
        "id": "ZRPfb46dMQFU",
        "outputId": "b8275dcd-6c21-411d-ad2e-7f086515414f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[29 61]\n",
            " [35 81]]\n",
            "score = 0.5631067961165048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def spToTensor(mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    mx = mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((mx.row, mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(mx.data)\n",
        "    shape = torch.Size(mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape).to(device)\n",
        "\n",
        "Adj_Matrix = spToTensor(Adj_Matrix)"
      ],
      "metadata": {
        "id": "ug5up_Hh5Uod"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(Adj_Matrix, '/content/drive/MyDrive/IR_Project/dataset/Adj931.pt')"
      ],
      "metadata": {
        "id": "SaVNE7W3DJu1"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "weights=[]\n",
        "row_list=[]\n",
        "col_list=[]\n",
        "Adj_Mat=[]\n",
        "windows=[]\n",
        "word_window_freq = {}\n",
        "word_pair_count = {}"
      ],
      "metadata": {
        "id": "znYK8MJ56aX5"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xt = torch.FloatTensor(3,2)"
      ],
      "metadata": {
        "id": "YCayTbC07IKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xt)"
      ],
      "metadata": {
        "id": "6kKFsSrbNifo",
        "outputId": "619251d7-446b-4deb-961a-fd5b95b78e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000e+00, 0.0000e+00],\n",
            "        [1.8788e+31, 1.7220e+22],\n",
            "        [2.1715e-18, 2.6309e+20]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features,  drop_out = 0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        print(self.weight.size())\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation =  activation\n",
        "\n",
        "    def reset_parameters(self,in_features, out_features):\n",
        "        stdv = np.sqrt(6.0/(in_features+out_features))\n",
        "        # stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "            # self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "    def forward(self, input, adj, feature_less = False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "metadata": {
        "id": "IQZVgPEvP9l8"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, n_layers = 2):\n",
        "        super(GCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.gc_list = []\n",
        "        if n_layers >= 2:\n",
        "            self.gc1 = GraphConvolution(nfeat, nhid, dropout, activation = nn.ReLU())\n",
        "            self.gc_list = nn.ModuleList([GraphConvolution(nhid, nhid, dropout, activation = nn.ReLU()) for _ in range(self.n_layers-2)])\n",
        "            self.gcf = GraphConvolution(nhid, nclass, dropout)\n",
        "        else:\n",
        "            self.gc1 = GraphConvolution(nfeat, nclass, dropout)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        if self.n_layers>=2:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "            for i in range(self.n_layers-2):\n",
        "                x = self.gc_list[i](x,adj)\n",
        "            x = self.gcf(x,adj)\n",
        "        else:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qRT2Xt9OQWOf"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_accuracy(predictions,labels):\n",
        "    pred = torch.argmax(predictions,-1).cpu().tolist()\n",
        "    lab = labels.cpu().tolist()\n",
        "    cor = 0\n",
        "    for i in range(len(pred)):\n",
        "        if pred[i] == lab[i]:\n",
        "            cor += 1\n",
        "    return cor/len(pred)"
      ],
      "metadata": {
        "id": "K-g-NUO6QgLz"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = GCN(nfeat=docs_size+vocab_size, nhid=HIDDEN_DIM, nclass=2, dropout=DROP_OUT,n_layers=NUM_LAYERS).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
      ],
      "metadata": {
        "id": "AYOhWieMQ07A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63229259-d496-4423-d255-b9b74180d4da"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([68805, 440])\n",
            "torch.Size([440, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=train_N\n",
        "test_size=test_N\n"
      ],
      "metadata": {
        "id": "9DMcrH3ScI3n"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.arange(docs_size+vocab_size)\n",
        "features = torch.FloatTensor(features).to(device)"
      ],
      "metadata": {
        "id": "f7hpx6T3exAP"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_val(train_pro=0.9):\n",
        "    real_train_size = int(train_pro*train_size)\n",
        "    val_size = train_size-real_train_size\n",
        "\n",
        "    idx_train = np.random.choice(train_size, real_train_size,replace=False)\n",
        "    idx_train.sort()\n",
        "    idx_val = []\n",
        "    pointer = 0\n",
        "    for v in range(train_size):\n",
        "        if pointer<len(idx_train) and idx_train[pointer] == v:\n",
        "            pointer +=1\n",
        "        else:\n",
        "            idx_val.append(v)\n",
        "    idx_test = range(train_N, train_N+test_N)\n",
        "    return idx_train, idx_val, idx_test\n",
        "\n",
        "idx_train, idx_val, idx_test = generate_train_val()"
      ],
      "metadata": {
        "id": "zmpy3UNHw4iy"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train_model(show_result = True):\n",
        "    val_loss = []\n",
        "    l_calc = 1\n",
        "    for epoch in tqdm(np.arange(NUM_EPOCHS)):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output= model(features, Adj_Matrix)\n",
        "        loss_train = criterion(output[idx_train], labels[idx_train])\n",
        "        acc_train = cal_accuracy(output[idx_train], labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        output = model(features, Adj_Matrix)\n",
        "\n",
        "        loss_val = criterion(output[idx_val], labels[idx_val])\n",
        "        val_loss.append(loss_val.item())\n",
        "        acc_val = cal_accuracy(output[idx_val], labels[idx_val])\n",
        "        if show_result:\n",
        "            print(  'Epoch: {:04d}'.format(epoch+1),\n",
        "                    'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "                    'acc_train: {:.4f}'.format(acc_train),\n",
        "                    'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "                    'acc_val: {:.4f}'.format(acc_val),\n",
        "                    'time: {:.4f}s'.format(time.time() - t))\n",
        "        # if epoch%10==0:\n",
        "        #   torch.save(model.state_dict(), \"/content/drive/MyDrive/IR_Project/dataset/model_latest.pth\")\n",
        "        if epoch > EARLY_STOPPING and np.min(val_loss[-EARLY_STOPPING:]) > np.min(val_loss[:-EARLY_STOPPING]) :\n",
        "            if show_result:\n",
        "                print(\"Early Stopping...\")\n",
        "            break\n",
        "        l_calc+=1\n",
        "    return l_calc\n",
        "l_calc = train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "8cbb2b04ce1d4669a753f2132fcfdb66",
            "59e0bcd5078f40cb89e58e4d2f79548e",
            "c2897dac25c840f49afbccc1c633a699",
            "b82e6f3fb03845ce80e43aab475ad9a8",
            "6bb3b1dfa7334bceaa9b62eabe1c3e1e",
            "9ba68ee429e84b418262d0e3167224e7",
            "9956777e999e47c9a08081bb49747403",
            "63088f3cef70497bbc1f406e263fae41",
            "179747534905486dbc4c862a5d926224",
            "75ed673536eb430aa02ccd17aa92e482",
            "aa0a65e917ce495d9b9a6de126e6a797"
          ]
        },
        "id": "VIYS5fK_cDCB",
        "outputId": "d9a5d27a-9470-4072-8923-4f767fc18386"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cbb2b04ce1d4669a753f2132fcfdb66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 loss_train: 0.6931 acc_train: 0.4806 loss_val: 0.6875 acc_val: 0.7333 time: 1.2032s\n",
            "Epoch: 0002 loss_train: 0.6812 acc_train: 0.9302 loss_val: 0.6602 acc_val: 0.6667 time: 1.1578s\n",
            "Epoch: 0003 loss_train: 0.6578 acc_train: 0.5271 loss_val: 0.6869 acc_val: 0.6000 time: 1.1592s\n",
            "Epoch: 0004 loss_train: 0.6247 acc_train: 0.8605 loss_val: 0.6514 acc_val: 0.8000 time: 1.1618s\n",
            "Epoch: 0005 loss_train: 0.5737 acc_train: 1.0000 loss_val: 0.6040 acc_val: 0.8000 time: 1.1633s\n",
            "Epoch: 0006 loss_train: 0.5222 acc_train: 0.9612 loss_val: 0.6043 acc_val: 0.8000 time: 1.1670s\n",
            "Epoch: 0007 loss_train: 0.4551 acc_train: 1.0000 loss_val: 0.6135 acc_val: 0.7333 time: 1.1715s\n",
            "Epoch: 0008 loss_train: 0.3927 acc_train: 0.9922 loss_val: 0.5597 acc_val: 0.8000 time: 1.1750s\n",
            "Epoch: 0009 loss_train: 0.3233 acc_train: 1.0000 loss_val: 0.5089 acc_val: 0.8667 time: 1.1794s\n",
            "Epoch: 0010 loss_train: 0.2643 acc_train: 1.0000 loss_val: 0.5164 acc_val: 0.8000 time: 1.1792s\n",
            "Epoch: 0011 loss_train: 0.2044 acc_train: 1.0000 loss_val: 0.5387 acc_val: 0.8000 time: 1.1848s\n",
            "Epoch: 0012 loss_train: 0.1573 acc_train: 1.0000 loss_val: 0.5026 acc_val: 0.8000 time: 1.1824s\n",
            "Epoch: 0013 loss_train: 0.1150 acc_train: 1.0000 loss_val: 0.4529 acc_val: 0.8667 time: 1.1849s\n",
            "Epoch: 0014 loss_train: 0.0849 acc_train: 1.0000 loss_val: 0.4458 acc_val: 0.8667 time: 1.1865s\n",
            "Epoch: 0015 loss_train: 0.0611 acc_train: 1.0000 loss_val: 0.4815 acc_val: 0.8000 time: 1.1901s\n",
            "Epoch: 0016 loss_train: 0.0428 acc_train: 1.0000 loss_val: 0.5245 acc_val: 0.8000 time: 1.1922s\n",
            "Epoch: 0017 loss_train: 0.0287 acc_train: 1.0000 loss_val: 0.5415 acc_val: 0.8000 time: 1.1956s\n",
            "Epoch: 0018 loss_train: 0.0210 acc_train: 1.0000 loss_val: 0.5289 acc_val: 0.8000 time: 1.1999s\n",
            "Epoch: 0019 loss_train: 0.0139 acc_train: 1.0000 loss_val: 0.5074 acc_val: 0.8000 time: 1.2079s\n",
            "Epoch: 0020 loss_train: 0.0095 acc_train: 1.0000 loss_val: 0.4936 acc_val: 0.8000 time: 1.2046s\n",
            "Epoch: 0021 loss_train: 0.0069 acc_train: 1.0000 loss_val: 0.4898 acc_val: 0.8000 time: 1.2142s\n",
            "Epoch: 0022 loss_train: 0.0052 acc_train: 1.0000 loss_val: 0.4983 acc_val: 0.8000 time: 1.2085s\n",
            "Epoch: 0023 loss_train: 0.0036 acc_train: 1.0000 loss_val: 0.5161 acc_val: 0.8000 time: 1.2135s\n",
            "Epoch: 0024 loss_train: 0.0028 acc_train: 1.0000 loss_val: 0.5421 acc_val: 0.8000 time: 1.2164s\n",
            "Early Stopping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_labels))\n",
        "print(len(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAJs9uExwPii",
        "outputId": "e54ecb47-c091-49f7-f174-f40a7c0e98b9"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, Adj_Matrix)\n",
        "    predictions = torch.argmax(output[idx_test],-1).cpu().tolist()\n",
        "    acc = accuracy_score(test_labels,predictions)\n",
        "    f11 = f1_score(test_labels,predictions, average='macro')\n",
        "    f12 = f1_score(test_labels,predictions, average = 'weighted')\n",
        "    return acc, f11, f12\n",
        "\n",
        "(acc, f11, f12) = test()\n",
        "print(\"Accuracy =\",acc)\n",
        "print(\"Macro F-1 =\",f11)\n",
        "print(\"Weighted =\",f12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkspyBacv0g5",
        "outputId": "eab98dc7-5515-4925-8347-7f953167803b"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.8225806451612904\n",
            "Macro F-1 = 0.8168143969916735\n",
            "Weighted = 0.8252016670565708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/drive/MyDrive/IR_Project/dataset/Analysis.csv', 'a', newline='') \n",
        "writer = csv.writer(file) \n",
        "# writer.writerow([\"NUM_LAYERS\",\"HIDDEN_DIM\",\"DROP_OUT\",\"LR\",\"WEIGHT_DECAY\",\"EARLY_STOPPING\",\"NUM_EPOCHS\",\"train_ratio\",\"test_ratio\",\"wt_k\",\"wt_t\",\"wt_a\",\"window_size\",\"Accuracy\",\"F-1 Macro\",\"F-1 Weighted\",\"epochs_completed\"])\n",
        "writer.writerow([NUM_LAYERS,HIDDEN_DIM,DROP_OUT,LR,WEIGHT_DECAY,EARLY_STOPPING,NUM_EPOCHS,train_ratio,test_ratio,wt_k,wt_t,wt_a,window_size,acc,f11,f12,l_calc])\n",
        "file.close()\n"
      ],
      "metadata": {
        "id": "xy3PbsC57RCK"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vectors = []\n",
        "\n",
        "for doc in rows:\n",
        "  vec = nlp(doc[1]+\" \"+doc[2]+\" \"+doc[3])\n",
        "  doc_vectors.append(vec.vector)"
      ],
      "metadata": {
        "id": "xGV-_v0tHEvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx_unlabelled = range(N,N+200)\n",
        "r = list(idx_unlabelled)\n",
        "file = open('/content/drive/MyDrive/IR_Project/dataset/Unlabelled.csv', 'a', newline='') \n",
        "writer = csv.writer(file)\n",
        "# writer.writerow([\"ID\",\"Pred\"])\n",
        "def pred_unlabelled():\n",
        "  model.eval()\n",
        "  output = model(features, Adj_Matrix)\n",
        "  preds = torch.argmax(output[idx_unlabelled],-1).cpu().tolist()\n",
        "  for i in r:\n",
        "    writer.writerow([i,preds[i-N]])\n",
        "  return\n",
        "\n",
        "pred_unlabelled()\n",
        "file.close()"
      ],
      "metadata": {
        "id": "JGCzywbOX0YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(idx_unlabelled)\n",
        "print(r)"
      ],
      "metadata": {
        "id": "q8Ve5SQ0bNj5",
        "outputId": "54a01618-23e4-4d19-f3cd-e13b8948945c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "%matplotlib inline\n",
        "\n",
        "X = doc_vectors[:N] #KMeans\n",
        "km = KMeans(n_clusters=2)\n",
        "km.fit(X)\n",
        "km.predict(X)\n",
        "labels = km.labels_"
      ],
      "metadata": {
        "id": "1-hRo4Vf5WB0",
        "outputId": "2b15a35a-d61b-440e-fd5f-e1dc3c362cd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}